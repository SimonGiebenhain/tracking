{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ji5SL6sKny_k",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182.0
    },
    "outputId": "e6e44f38-c127-432a-b5cd-f77876b881d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100+Final+Exam+Review+2019.docx\n",
      " Detaillierte_Anforderungen_v0.4.docx\n",
      " Detaillierte_Anforderungen_v0.5.docx.gdoc\n",
      " MathsForDataScience.gsheet\n",
      "'MatrNr only MathsForDataScience.gsheet'\n",
      " pyquaternion\n",
      " seed_1591495843.txt.gdoc\n",
      "'Unbenannte Tabelle.gsheet'\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/gdrive/My Drive/'\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/gdrive/My Drive/pyquaternion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8vZxk5ee3jMl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gc\n",
    "from pyquaternion import Quaternion as Quaternion\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pb6Y68uD3oPO",
    "colab_type": "text"
   },
   "source": [
    "# TODO:\n",
    "## - make LoggerColab specific\n",
    "## - accomodate for cuda and cpu\n",
    "## - ultimately add parameter which determines to use colab or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BsVk0Ub_4DEE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "generated_data_dir = 'generated_training_data'\n",
    "MODEL_NAME = 'LSTM'\n",
    "TASK = 'PosQuatPred; '\n",
    "\n",
    "drop_some_dets = True\n",
    "add_false_positives = False\n",
    "use_const_pat = True\n",
    "\n",
    "if drop_some_dets:\n",
    "    TASK += 'Drop some detections; '\n",
    "if add_false_positives:\n",
    "    TASK += 'Add false positives; '\n",
    "if use_const_pat:\n",
    "    TASK += 'ConstantPattern; '\n",
    "else:\n",
    "    TASK += 'ChangingPattern; '\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.25\n",
    "\n",
    "CHECKPOINT_INTERVAL = 10\n",
    "save_model_every_interval = True\n",
    "save_best_model = True\n",
    "\n",
    "N_train = 200*BATCH_SIZE\n",
    "N_eval = int(N_train/10)\n",
    "\n",
    "T = 200\n",
    "\n",
    "fc1_det_dim = 250\n",
    "fc2_det_dim = 300\n",
    "fc3_det_dim = 300\n",
    "fc4_det_dim = 250\n",
    "fc1_pat_dim = 200\n",
    "fc2_pat_dim = 250\n",
    "fc3_pat_dim = 150\n",
    "#fc1_combo_dim = 300\n",
    "#fc2_combo_dim = 100\n",
    "hidden_dim = 75\n",
    "fc_out_1_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4MOqrN6_4O6e",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    return v / np.sum(v)\n",
    "\n",
    "\n",
    "def gen_folder_name(task, name):\n",
    "    if len(task) > 20:\n",
    "        short_task = re.sub('[^A-Z]', '', task)\n",
    "    else:\n",
    "        short_task = task\n",
    "    if len(name) > 20:\n",
    "        short_name = re.sub('[^A-Z]', '', name)\n",
    "    else:\n",
    "        short_name = name\n",
    "    now = datetime.now()\n",
    "    dt_str = now.strftime(\"%d.%m.%Y@%H:%M:%S\")\n",
    "    return short_name + '_' + short_task + '_' + dt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XFd_1_jJ4Vg4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class TrainingData():\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.X_train_shuffled = None\n",
    "        self.quat_train = None\n",
    "        self.pos_train = None\n",
    "        self.pattern_train = None\n",
    "\n",
    "        self.X_test = None\n",
    "        self.X_test_shuffled = None\n",
    "        self.quat_test = None\n",
    "        self.pos_test = None\n",
    "        self.pattern_test = None\n",
    "\n",
    "    def set_train_data(self, X, X_shuffled, quat, pos, pattern):\n",
    "        self.X_train = X\n",
    "        self.X_train_shuffled = X_shuffled\n",
    "        self.quat_train = quat\n",
    "        self.pos_train = pos\n",
    "        self.pattern_train = pattern\n",
    "\n",
    "    def set_test_data(self, X, X_shuffled, quat, pos, pattern):\n",
    "        self.X_test = X\n",
    "        self.X_test_shuffled = X_shuffled\n",
    "        self.quat_test = quat\n",
    "        self.pos_test = pos\n",
    "        self.pattern_test = pattern\n",
    "\n",
    "    def load_data(self, dir_name):\n",
    "        self.X_train = np.load(dir_name + '/X_train.npy')\n",
    "        self.X_train_shuffled = np.load(dir_name + '/X_train_shuffled.npy')\n",
    "        self.quat_train = np.load(dir_name + '/quat_train.npy')\n",
    "        self.pos_train = np.load(dir_name + '/pos_train.npy')\n",
    "        self.pattern_train = np.load(dir_name + '/pattern_train.npy')\n",
    "\n",
    "        self.X_test = np.load(dir_name + '/X_test.npy')\n",
    "        self.X_test_shuffled = np.load(dir_name + '/X_test_shuffled.npy')\n",
    "        self.quat_test = np.load(dir_name + '/quat_test.npy')\n",
    "        self.pos_test = np.load(dir_name + '/pos_test.npy')\n",
    "        self.pattern_test = np.load(dir_name + '/pattern_test.npy')\n",
    "\n",
    "    def save_data(self, dir_name):\n",
    "        np.save(dir_name + '/X_train.npy', self.X_train)\n",
    "        np.save(dir_name + '/X_train_shuffled', self.X_train_shuffled)\n",
    "        np.save(dir_name + '/quat_train', self.quat_train)\n",
    "        np.save(dir_name + '/pos_train.npy', self.pos_train)\n",
    "        np.save(dir_name + '/pattern_train.npy', self.pattern_train)\n",
    "\n",
    "        np.save(dir_name + '/X_test.npy', self.X_test)\n",
    "        np.save(dir_name + '/X_test_shuffled', self.X_test_shuffled)\n",
    "        np.save(dir_name + '/quat_test', self.quat_test)\n",
    "        np.save(dir_name + '/pos_test.npy', self.pos_test)\n",
    "        np.save(dir_name + '/pattern_test.npy', self.pattern_test)\n",
    "\n",
    "    def convert_to_torch(self):\n",
    "        self.X_train = torch.from_numpy(self.X_train).float().cuda()\n",
    "        self.X_train_shuffled = torch.from_numpy(self.X_train_shuffled).float().cuda()\n",
    "        self.quat_train = torch.from_numpy(self.quat_train).float().cuda()\n",
    "        self.pos_train = torch.from_numpy(self.pos_train).float().cuda()\n",
    "        self.pattern_train = torch.from_numpy(self.pattern_train).float().cuda()\n",
    "\n",
    "        self.X_test = torch.from_numpy(self.X_test).float().cuda()\n",
    "        self.X_test_shuffled = torch.from_numpy(self.X_test_shuffled).float().cuda()\n",
    "        self.quat_test = torch.from_numpy(self.quat_test).float().cuda()\n",
    "        self.pos_test = torch.from_numpy(self.pos_test).float().cuda()\n",
    "        self.pattern_test = torch.from_numpy(self.pattern_test).float().cuda()\n",
    "\n",
    "    def convert_to_numpy(self):\n",
    "        self.X_train = self.X_train.numpy()\n",
    "        self.X_train_shuffled = self.X_train_shuffled.numpy()\n",
    "        self.quat_train = self.quat_train.numpy()\n",
    "        self.pos_train = self.pos_train.numpy()\n",
    "        self.pattern_train = self.pattern_train.numpy()\n",
    "\n",
    "        self.X_test = self.X_test.numpy()\n",
    "        self.X_test_shuffled = self.X_test_shuffled.numpy()\n",
    "        self.quat_test = self.quat_test.numpy()\n",
    "        self.pos_test = self.pos_test.numpy()\n",
    "        self.pattern_test = self.pattern_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bQVeJG9C4bmo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class HyperParams():\n",
    "    def __init__(self, n_train, n_test, T, batch_size, optimizer, init_learning_rate, lr_scheduler, lr_scheduler_params,\n",
    "                       dropout_rate, batch_norm_type, loss_type, comments):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_train = n_train\n",
    "        self.n_test = n_test\n",
    "        self.T = T\n",
    "        self.optimizer = type(optimizer).__name__\n",
    "        self.init_learning_rate = init_learning_rate\n",
    "        self.lr_scheduler = type(lr_scheduler).__name__\n",
    "        self.lr_scheduler_params = ''\n",
    "        for key in lr_scheduler_params:\n",
    "            self.lr_scheduler_params += key + ': ' + str(lr_scheduler_params[key]) + ', '\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.batch_norm_type = batch_norm_type\n",
    "        self.loss_type = loss_type\n",
    "        self.comments = comments\n",
    "\n",
    "\n",
    "    def gen_string(self):\n",
    "        description = 'Description of hyper parameters of the model: \\n'\n",
    "        description = description + 'Batch size: \\t {} \\n'.format(self.batch_size)\n",
    "        description = description + 'Train size: \\t {} \\n'.format(self.n_train)\n",
    "        description = description + 'Test size: \\t {} \\n'.format(self.n_test)\n",
    "        description = description + 'Sequence length: \\t {} \\n'.format(self.T)\n",
    "        description = description + 'Optimizer: \\t ' + self.optimizer + '\\n'\n",
    "        description = description + 'Initial LR: \\t {} \\n'.format(self.init_learning_rate)\n",
    "        description = description + 'LR scheduler: \\t ' + self.lr_scheduler + '\\n'\n",
    "        description = description + 'Scheduler params: \\t' + self.lr_scheduler_params + '\\n'\n",
    "        description = description + 'Dropout rate: \\t {} \\n'.format(self.dropout_rate)\n",
    "        description = description + 'Batch norm: \\t ' + self.batch_norm_type + '\\n'\n",
    "        description = description + 'Loss type: \\t ' + self.loss_type + '\\n'\n",
    "        description = description + 'Comments: \\t ' + self.comments + '\\n'\n",
    "        return description\n",
    "\n",
    "\n",
    "class TrainingLogger():\n",
    "    def __init__(self, name, task, hyper_params):\n",
    "        self.name = name\n",
    "        self.task = task\n",
    "        self.best_model = None\n",
    "        self.best_val_loss = np.Inf\n",
    "        self.best_pose_loss = np.Inf\n",
    "        self.hyper_params = hyper_params\n",
    "\n",
    "        self.progress_dict = {'train_pose': [], 'train_quat': [], 'train_pos': [],\n",
    "                              'test_pose':  [], 'test_quat':  [], 'test_pos':  [],\n",
    "                              'learning_rate': []}\n",
    "\n",
    "        self.folder_name = gen_folder_name(task, name)\n",
    "        self.model = model\n",
    "\n",
    "        working_dir = os.getcwd()\n",
    "        path = working_dir + '/' + self.folder_name\n",
    "        os.mkdir(path)\n",
    "\n",
    "    def log_epoch(self, train_pose, train_quat, train_pos, test_pose, test_quat, test_pos, model, lr):\n",
    "        self.progress_dict['train_pose'].append(train_pose)\n",
    "        self.progress_dict['train_quat'].append(train_quat)\n",
    "        self.progress_dict['train_pos'].append(train_pos)\n",
    "        self.progress_dict['test_pose'].append(test_pose)\n",
    "        self.progress_dict['test_quat'].append(test_quat)\n",
    "        self.progress_dict['test_pos'].append(test_pos)\n",
    "        self.progress_dict['learning_rate'].append(lr)\n",
    "\n",
    "        if self.best_pose_loss > test_pose:\n",
    "            self.best_pose_loss = test_pose\n",
    "\n",
    "        val_loss = test_pos + test_quat\n",
    "        if save_best_model and val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            torch.save(model, self.folder_name + '/model_best.npy')\n",
    "        epoch = len(self.progress_dict['train_pose'])\n",
    "        if save_model_every_interval and epoch % CHECKPOINT_INTERVAL == 0:\n",
    "            torch.save(model, self.folder_name + '/model_epoch_{}'.format(epoch))\n",
    "\n",
    "    def save_log(self):\n",
    "        description = self.hyper_params.gen_string()\n",
    "        description = 'MODEL: \\t' + self.name + '\\n TASK: \\t' + self.task + '\\n' + description\n",
    "        description = description + 'Best pose loss: \\t {loss:1.8f} \\n'.format(loss=self.best_pose_loss)\n",
    "        file = open(self.folder_name + '/' + 'hyper_params.txt', 'w+')\n",
    "        file.write(description)\n",
    "        file.close()\n",
    "\n",
    "        training_progress_df = pd.DataFrame.from_dict(self.progress_dict)\n",
    "        training_progress_df.to_csv(self.folder_name + '/' + 'training_progress.csv')\n",
    "\n",
    "        training_progress = training_progress_df.to_numpy()\n",
    "        print(np.shape(training_progress))\n",
    "        for k, key in enumerate(self.progress_dict):\n",
    "            if key == 'learning_rate':\n",
    "                continue\n",
    "            if k < 3:\n",
    "                c_train = np.array([1, k*0.2, 0, 1])\n",
    "                plt.plot(training_progress[:, k], c=c_train, label=key)\n",
    "            else:\n",
    "                c_test = np.array([0, k*0.2, 1, 1])\n",
    "                plt.plot(training_progress[:, k], c=c_test, label=key)\n",
    "        plt.legend()\n",
    "        plt.savefig(self.folder_name + '/training_progress.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ZUApV8iX4j03",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def gen_pattern_constant(N):\n",
    "    marker1 = np.array([0, 0, 0])\n",
    "    marker2 = np.array([0, 0, 0.5])\n",
    "    marker3 = np.array([-0.7, -1, 0])\n",
    "    marker4 = np.array([1.1, -1, 0.8])\n",
    "\n",
    "    pattern = np.stack([marker1, marker2, marker3, marker4], axis=0)\n",
    "\n",
    "    stacked_marker1 = np.tile(marker1, reps=(T, N, 1))\n",
    "    stacked_marker2 = np.tile(marker2, reps=(T, N, 1))\n",
    "    stacked_marker3 = np.tile(marker3, reps=(T, N, 1))\n",
    "    stacked_marker4 = np.tile(marker4, reps=(T, N, 1))\n",
    "\n",
    "    pattern = np.stack([stacked_marker1, stacked_marker2, stacked_marker3, stacked_marker4], axis=2)\n",
    "\n",
    "    #stacked_marker1 = torch.from_numpy(stacked_marker1).float()\n",
    "    #stacked_marker2 = torch.from_numpy(stacked_marker2).float()\n",
    "    #stacked_marker3 = torch.from_numpy(stacked_marker3).float()\n",
    "    #stacked_marker4 = torch.from_numpy(stacked_marker4).float()\n",
    "\n",
    "    return pattern, stacked_marker1, stacked_marker2, stacked_marker3, stacked_marker4\n",
    "\n",
    "\n",
    "def gen_pattern(N):\n",
    "\n",
    "    # one marker is always the origin\n",
    "    marker1 = np.zeros([T, N, 3])\n",
    "\n",
    "    # The others have to be generated such that they span a 3-dim space\n",
    "    marker2 = np.random.uniform(-1, 1, [1, N, 3])\n",
    "\n",
    "    marker3 = np.random.uniform(-1, 1, [1, N, 3])\n",
    "    ortho_marker2 = np.stack([marker2[:,:,1] + marker2[:, :, 2], -marker2[:, :, 0], -marker2[:, :, 0]], axis=2)\n",
    "    marker3 = (marker3 + ortho_marker2) / 2\n",
    "\n",
    "    ortho_marker23 = np.cross(marker2, marker3)\n",
    "    scale_marker2 = np.random.uniform(-1, 1, [1, N, 1])\n",
    "    scale_marker3 = np.random.uniform(-1, 1, [1, N, 1])\n",
    "    scale_ortho = np.random.uniform(0.1, 1, [1, N, 1]) * np.random.choice([-1, 1], size=[1, N, 1], replace=True)\n",
    "    marker4 = scale_marker2 * marker2 + scale_marker3 + marker3 + scale_ortho * ortho_marker23\n",
    "\n",
    "    marker2 = np.tile(marker2/10, [T, 1, 1])\n",
    "    marker3 = np.tile(marker3/10, [T, 1, 1])\n",
    "    marker4 = np.tile(marker4/10, [T, 1, 1])\n",
    "\n",
    "    pattern = np.stack([marker1, marker2, marker3, marker4], axis=2)\n",
    "\n",
    "    return pattern, marker1, marker2, marker3, marker4\n",
    "\n",
    "\n",
    "def gen_quats(length):\n",
    "    theta_range = np.random.uniform(1,2)\n",
    "    theta = np.linspace(-theta_range * np.pi, theta_range * np.pi, length)\n",
    "    z_range = np.random.randint(1,10)\n",
    "    z = np.random.uniform(1,3)*np.sin(np.linspace(0, z_range, length))\n",
    "    rx = np.abs(z) ** np.random.uniform(1.5,3)*np.abs(np.random.rand())  + 1\n",
    "    ry = np.abs(z) ** np.random.uniform(1.5,3)*np.abs(np.random.rand())  + 1\n",
    "    x = rx**1.5 * np.sin(theta)\n",
    "    y = ry**1.5 * np.cos(theta)\n",
    "    w = 1 + np.random.uniform(0.5, 4)*np.sin(theta)*np.cos(theta)**2\n",
    "    quats = np.stack([w, x, y, z], axis=1)\n",
    "    quats = quats / np.expand_dims(np.sqrt(np.sum(np.square(quats), axis=1)), axis=1)\n",
    "    #quats = np.tile(np.array([1, 0, 0, 0]), [length, 1])\n",
    "    return quats\n",
    "\n",
    "\n",
    "def Gen_Spirals(length, dims=2):\n",
    "    theta_range = np.random.randint(1,10)\n",
    "    theta = np.linspace(-theta_range * np.pi, theta_range * np.pi, length)\n",
    "    z_range = np.random.randint(15,45)\n",
    "    z = np.random.uniform(1,3)*np.sin(np.linspace(0, z_range, length))\n",
    "    rx = np.abs(z) ** np.random.uniform(1.5,3)*np.abs(np.random.rand())  + 1\n",
    "    ry = np.abs(z) ** np.random.uniform(1.5,3)*np.abs(np.random.rand())  + 1\n",
    "    x = rx**1.5 * np.sin(theta)\n",
    "    y = ry**1.5 * np.cos(theta)\n",
    "\n",
    "    return np.stack([x,y,z], axis=1) + 5*np.random.uniform(low=-5, high=5, size=[1,dims])\n",
    "\n",
    "\n",
    "def scale_trajectory(trajectory):\n",
    "    max_pos = np.max(trajectory, axis=0)\n",
    "    min_pos = np.min(trajectory, axis=0)\n",
    "    movement_range = max_pos - min_pos\n",
    "    return  5 * (trajectory / movement_range)\n",
    "\n",
    "\n",
    "def center_trajectory(trajectory):\n",
    "    center = np.mean(trajectory, axis=0)\n",
    "    return trajectory - center\n",
    "\n",
    "\n",
    "def gen_pos(N):\n",
    "\n",
    "    pos = np.zeros([T, N, 3], dtype=np.float32)\n",
    "\n",
    "    for n in range(N):\n",
    "        trajectory = Gen_Spirals(T, 3)\n",
    "        trajectory = center_trajectory(trajectory)\n",
    "        trajectory = scale_trajectory(trajectory)\n",
    "        pos[:, n, :] = trajectory\n",
    "\n",
    "    return pos\n",
    "\n",
    "\n",
    "def qrot(q, v):\n",
    "    #TODO can I change this function to also work with constant v and changing quaternions?\n",
    "    # if not just tile/stack v accordingly\n",
    "    \"\"\"\n",
    "    Rotate vector(s) v about the rotation described by quaternion(s) q.\n",
    "    Expects a tensor of shape (*, 4) for q and a tensor of shape (*, 3) for v,\n",
    "    where * denotes any number of dimensions.\n",
    "    Returns a tensor of shape (*, 3).+\n",
    "\n",
    "    source: https://github.com/facebookresearch/QuaterNet/blob/master/common/quaternion.py\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    assert v.shape[-1] == 3\n",
    "    if not q.shape[:-1] == v.shape[:-1]:\n",
    "        q_batch_size = list(q.shape)[1]\n",
    "        size = int(q_batch_size/BATCH_SIZE)\n",
    "        v = v.repeat([1, size, 1])\n",
    "\n",
    "    original_shape = list(v.shape)\n",
    "    q = q.view(-1, 4)\n",
    "    v = v.view(-1, 3)\n",
    "\n",
    "    qvec = q[:, 1:]\n",
    "    uv = torch.cross(qvec, v, dim=1)\n",
    "    uuv = torch.cross(qvec, uv, dim=1)\n",
    "    return (v + 2 * (q[:, :1] * uv + uuv)).view(original_shape)\n",
    "\n",
    "\n",
    "# TODO: vecotrize with qrot() and by shuffling markers while generating them\n",
    "def gen_training_data(N_train, N_test):\n",
    "\n",
    "    quat_train = np.zeros([T, N_train, 4], dtype=np.float32)\n",
    "    quat_test = np.zeros([T, N_test, 4], dtype=np.float32)\n",
    "\n",
    "    for n in range(N_train):\n",
    "        quat_train[:, n, :] = gen_quats(T)\n",
    "\n",
    "    for n in range(N_test):\n",
    "        quat_test[:, n, :] = gen_quats(T)\n",
    "\n",
    "    pos_train = gen_pos(N_train)\n",
    "    pos_test = gen_pos(N_test)\n",
    "\n",
    "    pos_train_stacked = np.tile(pos_train, [1, 1, 4])\n",
    "    pos_test_stacked = np.tile(pos_test, [1, 1, 4])\n",
    "\n",
    "    if use_const_pat:\n",
    "        pattern_train, _, _, _, _ = gen_pattern_constant(N_train)\n",
    "        pattern_test, _, _, _, _ = gen_pattern_constant(N_test)\n",
    "    else:\n",
    "        pattern_train, _, _, _, _ = gen_pattern(N_train)\n",
    "        pattern_test, _, _, _, _ = gen_pattern(N_test)\n",
    "\n",
    "    X_train = np.zeros([T, N_train, 12])\n",
    "    X_train_shuffled = np.zeros([T, N_train, 12])\n",
    "    X_test = np.zeros([T, N_test, 12])\n",
    "    X_test_shuffled = np.zeros([T, N_test, 12])\n",
    "\n",
    "    for t in range(T):\n",
    "        for n in range(N_train):\n",
    "            p_train = pattern_train[t, n, :, :]\n",
    "            p_train_copy = np.copy(p_train)\n",
    "\n",
    "            q = Quaternion(quat_train[t, n, :])\n",
    "            np.random.shuffle(p_train_copy)\n",
    "            rotated_pattern = (q.rotation_matrix @ p_train_copy.T).T\n",
    "            if drop_some_dets and np.random.uniform(0,1) < 0.5:\n",
    "                rotated_pattern[3,:] = np.array([-1000,-1000,-1000])\n",
    "                if drop_some_dets and np.random.uniform(0, 1) < 0.5:\n",
    "                    rotated_pattern[2, :] = np.array([-1000, -1000, -1000])\n",
    "            X_train_shuffled[t, n, :] = np.reshape(rotated_pattern, -1)\n",
    "\n",
    "            rotated_pattern = (q.rotation_matrix @ p_train.T).T\n",
    "            X_train[t, n, :] = np.reshape(rotated_pattern, -1)\n",
    "\n",
    "    for t in range(T):\n",
    "        for n in range(N_test):\n",
    "            p_test = pattern_test[t, n, :, :]\n",
    "            p_test_copy = np.copy(p_test)\n",
    "\n",
    "            q = Quaternion(quat_test[t, n, :])\n",
    "            np.random.shuffle(p_test_copy)\n",
    "            rotated_pattern = (q.rotation_matrix @ p_test_copy.T).T\n",
    "            if drop_some_dets and np.random.uniform(0,1) < 0.5:\n",
    "                rotated_pattern[3,:] = np.array([-1000,-1000,-1000])\n",
    "                if drop_some_dets and np.random.uniform(0, 1) < 0.5:\n",
    "                    rotated_pattern[2, :] = np.array([-1000, -1000, -1000])\n",
    "            X_test_shuffled[t, n, :] = np.reshape(rotated_pattern, -1)\n",
    "\n",
    "            rotated_pattern = (q.rotation_matrix @ p_test.T).T\n",
    "            X_test[t, n, :] = np.reshape(rotated_pattern, -1)\n",
    "\n",
    "    X_train = X_train + pos_train_stacked\n",
    "    X_train_shuffled = X_train_shuffled + pos_train_stacked\n",
    "    X_test = X_test + pos_test_stacked\n",
    "    X_test_shuffled = X_test_shuffled + pos_test_stacked\n",
    "\n",
    "    data = TrainingData()\n",
    "    data.set_train_data(X_train, X_train_shuffled, quat_train, pos_train, pattern_train)\n",
    "    data.set_test_data(X_test, X_test_shuffled, quat_test, pos_test, pattern_test)\n",
    "    #TODO: data.save_data(generated_data_dir)\n",
    "    data.convert_to_torch()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_training_data():\n",
    "    data = TrainingData()\n",
    "    data.load_data(generated_data_dir)\n",
    "    global T, N_train, N_eval\n",
    "    T = np.shape(data.X_train)[0]\n",
    "    N_train = np.shape(data.X_train)[1]\n",
    "    N_eval = np.shape(data.X_test)[1]\n",
    "    data.convert_to_torch()\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z1g_WKXa41kf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    },
    "outputId": "8bac3ea7-2b10-4b04-8ce9-cff259d9abaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CUDA DEVICE\n",
      "Tesla K80\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# todo custom LSTM-cell\n",
    "class LSTMTracker(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(LSTMTracker, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.fc1_det = nn.Linear(12, fc1_det_dim)\n",
    "        self.fc2_det = nn.Linear(fc1_det_dim, fc2_det_dim)\n",
    "        self.fc3_det = nn.Linear(fc2_det_dim, fc3_det_dim)\n",
    "        self.fc4_det = nn.Linear(fc3_det_dim, fc4_det_dim)\n",
    "\n",
    "        if not use_const_pat:\n",
    "            self.fc1_pat = nn.Linear(12, fc1_pat_dim)\n",
    "            self.fc2_pat = nn.Linear(fc1_pat_dim, fc2_pat_dim)\n",
    "            self.fc3_pat = nn.Linear(fc2_pat_dim, fc3_pat_dim)\n",
    "\n",
    "        #self.fc1_combo = nn.Linear(fc2_pat_dim + fc3_det_dim, fc1_combo_dim)\n",
    "        #self.fc2_combo = nn.Linear(fc1_combo_dim, fc2_combo_dim)\n",
    "\n",
    "        if use_const_pat:\n",
    "            self.lstm = nn.LSTM(fc4_det_dim, hidden_dim)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(fc4_det_dim + fc3_pat_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2quat1 = nn.Linear(hidden_dim, fc_out_1_size)\n",
    "        self.hidden2quat2 = nn.Linear(fc_out_1_size, 4)\n",
    "\n",
    "        self.hidden2pos = nn.Linear(hidden_dim, 3)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "\n",
    "    def forward(self, detections, patterns):\n",
    "        marker1 = patterns[:, :, 0, :].contiguous()\n",
    "        marker2 = patterns[:, :, 1, :].contiguous()\n",
    "        marker3 = patterns[:, :, 2, :].contiguous()\n",
    "        marker4 = patterns[:, :, 3, :].contiguous()\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1_det(detections)))\n",
    "        x = self.dropout(F.relu(self.fc2_det(x)))\n",
    "        x = self.dropout(F.relu(self.fc3_det(x)))\n",
    "        x = self.dropout(F.relu(self.fc4_det(x)))\n",
    "\n",
    "        if not use_const_pat:\n",
    "            x_pat = self.dropout(F.relu(self.fc1_pat(patterns.view(T-1, -1, 12))))\n",
    "            x_pat = self.dropout(F.relu(self.fc2_pat(x_pat)))\n",
    "            x_pat = self.dropout(F.relu(self.fc3_pat(x_pat)))\n",
    "            x = torch.cat([x, x_pat], dim=2)\n",
    "\n",
    "        #x_combo = self.dropout(F.relu(self.fc1_combo(x_combo)))\n",
    "        #x_combo = self.dropout(F.relu(self.fc2_combo(x_combo)))\n",
    "\n",
    "        #x = torch.cat([x_det, x_pat], dim=2)\n",
    "\n",
    "        #x = x_det - x_pat\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = F.relu(self.hidden2quat1(lstm_out))\n",
    "        quat_space = self.hidden2quat2(x)\n",
    "        pos_space = self.hidden2pos(lstm_out)\n",
    "        # maybe leave out wenn not using pose error\n",
    "        quat_norm = torch.sqrt(torch.sum(torch.pow(quat_space, 2, ), dim=2))\n",
    "        quat_space = quat_space / torch.unsqueeze(quat_norm, dim=2)\n",
    "\n",
    "        rotated_marker1 = qrot(quat_space, marker1) + pos_space\n",
    "        rotated_marker2 = qrot(quat_space, marker2) + pos_space\n",
    "        rotated_marker3 = qrot(quat_space, marker3) + pos_space\n",
    "        rotated_marker4 = qrot(quat_space, marker4) + pos_space\n",
    "        rotated_pattern = torch.cat([rotated_marker1,\n",
    "                                     rotated_marker2,\n",
    "                                     rotated_marker3,\n",
    "                                     rotated_marker4], dim=2)\n",
    "\n",
    "        return quat_space, pos_space, rotated_pattern\n",
    "\n",
    "model = LSTMTracker(hidden_dim)\n",
    "if torch.cuda.is_available():\n",
    "  print('USING CUDA DEVICE')\n",
    "  model.cuda()\n",
    "  device = torch.device('cuda')\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print('Memory Usage:')\n",
    "  print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "  print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "else:\n",
    "  print('CUDA NOT AVAILABLE')\n",
    "\n",
    "\n",
    "# TODO: respect antipodal pair as well!\n",
    "loss_function_pose = nn.MSELoss()\n",
    "loss_function_quat = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler_params = {'mode': 'min', 'factor': 0.5, 'patience': 0}\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=lr_scheduler_params['mode'],\n",
    "                                                       factor=lr_scheduler_params['factor'],\n",
    "                                                       patience=lr_scheduler_params['patience'],\n",
    "                                                       verbose=False, min_lr=1e-08)\n",
    "\n",
    "hyper_params = HyperParams(N_train, N_eval, T, BATCH_SIZE, optimizer, LEARNING_RATE, scheduler, lr_scheduler_params,\n",
    "                           DROPOUT_RATE, 'NONE', 'l2 on pos + 5* l1 on quat', '')\n",
    "logger = TrainingLogger(MODEL_NAME, TASK, hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bFxgkpQjlTcb",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    data = gen_training_data(N_train, N_eval)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      print('USING CUDA DEVICE')\n",
    "      model.cuda()\n",
    "      device = torch.device('cuda')\n",
    "      print(torch.cuda.get_device_name(0))\n",
    "      print('Memory Usage:')\n",
    "      print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "      print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    else:\n",
    "      print('CUDA NOT AVAILABLE')\n",
    "  \n",
    "    for gci in range(10):\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        model.train()\n",
    "\n",
    "        batches = torch.split(data.X_train_shuffled, BATCH_SIZE, 1)\n",
    "        quat_truth_batches = torch.split(data.quat_train, BATCH_SIZE, 1)\n",
    "        pos_truth_batches = torch.split(data.pos_train, BATCH_SIZE, 1)\n",
    "        batches_not_shuffled = torch.split(data.X_train, BATCH_SIZE, 1)\n",
    "        pattern_batches = torch.split(data.pattern_train, BATCH_SIZE, 1)\n",
    "        avg_loss_pose = 0\n",
    "        avg_loss_quat = 0\n",
    "        avg_loss_pos = 0\n",
    "        \n",
    "        for batch, quat_truth_batch, pos_truth_batch, batch_not_shuffled, pattern_batch in zip(batches, quat_truth_batches, pos_truth_batches, batches_not_shuffled, pattern_batches):\n",
    "            model.zero_grad()\n",
    "\n",
    "            pred_quat, pred_pos, pred_markers = model(batch[:-1, :, :], pattern_batch[:-1, :, :, :])\n",
    "\n",
    "            loss_pose = loss_function_pose(pred_markers, batch_not_shuffled[1:, :, :])\n",
    "            loss_quat = loss_function_quat(pred_quat, quat_truth_batch[1:, :, :])\n",
    "            loss_pos = loss_function_pose(pred_pos, pos_truth_batch[1:, :, :])\n",
    "\n",
    "            loss = loss_pos + loss_quat\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss_pose += loss_pose\n",
    "            avg_loss_quat += loss_quat\n",
    "            avg_loss_pos += loss_pos\n",
    "        avg_loss_pose /= len(batches)\n",
    "        avg_loss_quat /= len(batches)\n",
    "        avg_loss_pos /= len(batches)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_quat, pred_pos, preds  = model(data.X_test_shuffled[:-1,:,:], data.pattern_test[:-1, :, :, :])\n",
    "            loss_pose = loss_function_pose(preds, data.X_test[1:,:,:])\n",
    "            loss_quat = loss_function_quat(pred_quat, data.quat_test[1:, :, :])\n",
    "            loss_pos = loss_function_pose(pred_pos, data.pos_test[1:, :, :])\n",
    "            val_loss = loss_pos + loss_quat\n",
    "            for param_group in optimizer.param_groups:\n",
    "                learning_rate = param_group['lr']\n",
    "                print(\"Epoch: {epoch:2d}, Learning Rate: {learning_rate:1.8f} \\n TrainPoseLoss: {train_pose:2.4f}, TrainQuatLoss: {train_quat:2.4f}  TrainPosLoss: {train_pos:2.4f} \\t TestPoseLoss: {test_pose:2.4f}, TestQuatLoss: {test_quat:2.4f}, TestPosLoss: {test_pos:2.4f}\".format(\n",
    "                    epoch=epoch, learning_rate=learning_rate, train_pose=avg_loss_pose.data, train_quat=avg_loss_quat.data, train_pos=avg_loss_pos.data, test_pose=loss_pose, test_quat=loss_quat, test_pos=loss_pos.data))\n",
    "            scheduler.step(val_loss)\n",
    "            #logger.log_epoch(avg_loss_pose, avg_loss_quat, avg_loss_pos, loss_pose, loss_quat, loss_pos, model, learning_rate)\n",
    "\n",
    "    #logger.save_log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "crRELh3Old9Q",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "outputId": "42f07cd4-69a2-40ce-e093-446e78fc0422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CUDA DEVICE\n",
      "Tesla K80\n",
      "Memory Usage:\n",
      "Allocated: 0.4 GB\n",
      "Cached:    0.4 GB\n",
      "Epoch:  1, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 1.0704, TrainQuatLoss: 0.4117  TrainPosLoss: 0.5278 \t TestPoseLoss: 0.7058, TestQuatLoss: 0.3910, TestPosLoss: 0.2280\n",
      "Epoch:  2, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.6231, TrainQuatLoss: 0.3238  TrainPosLoss: 0.2555 \t TestPoseLoss: 0.4541, TestQuatLoss: 0.2519, TestPosLoss: 0.1980\n",
      "Epoch:  3, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.4636, TrainQuatLoss: 0.2413  TrainPosLoss: 0.2209 \t TestPoseLoss: 0.3882, TestQuatLoss: 0.2270, TestPosLoss: 0.1737\n",
      "Epoch:  4, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.4051, TrainQuatLoss: 0.2205  TrainPosLoss: 0.1983 \t TestPoseLoss: 0.3367, TestQuatLoss: 0.2071, TestPosLoss: 0.1550\n",
      "Epoch:  5, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.3604, TrainQuatLoss: 0.2038  TrainPosLoss: 0.1807 \t TestPoseLoss: 0.2987, TestQuatLoss: 0.1930, TestPosLoss: 0.1404\n",
      "Epoch:  6, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.3275, TrainQuatLoss: 0.1919  TrainPosLoss: 0.1662 \t TestPoseLoss: 0.2662, TestQuatLoss: 0.1792, TestPosLoss: 0.1285\n",
      "Epoch:  7, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.3019, TrainQuatLoss: 0.1821  TrainPosLoss: 0.1553 \t TestPoseLoss: 0.2508, TestQuatLoss: 0.1734, TestPosLoss: 0.1218\n",
      "Epoch:  8, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.2801, TrainQuatLoss: 0.1730  TrainPosLoss: 0.1463 \t TestPoseLoss: 0.2340, TestQuatLoss: 0.1648, TestPosLoss: 0.1152\n",
      "Epoch:  9, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.2656, TrainQuatLoss: 0.1664  TrainPosLoss: 0.1397 \t TestPoseLoss: 0.2153, TestQuatLoss: 0.1550, TestPosLoss: 0.1090\n",
      "Epoch: 10, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.2492, TrainQuatLoss: 0.1586  TrainPosLoss: 0.1331 \t TestPoseLoss: 0.2016, TestQuatLoss: 0.1464, TestPosLoss: 0.1036\n",
      "Epoch: 11, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.2343, TrainQuatLoss: 0.1506  TrainPosLoss: 0.1276 \t TestPoseLoss: 0.1885, TestQuatLoss: 0.1392, TestPosLoss: 0.0982\n",
      "Epoch: 12, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.2199, TrainQuatLoss: 0.1421  TrainPosLoss: 0.1228 \t TestPoseLoss: 0.1706, TestQuatLoss: 0.1266, TestPosLoss: 0.0928\n",
      "Epoch: 13, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.2052, TrainQuatLoss: 0.1329  TrainPosLoss: 0.1179 \t TestPoseLoss: 0.1592, TestQuatLoss: 0.1184, TestPosLoss: 0.0891\n",
      "Epoch: 14, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1921, TrainQuatLoss: 0.1248  TrainPosLoss: 0.1133 \t TestPoseLoss: 0.1489, TestQuatLoss: 0.1117, TestPosLoss: 0.0859\n",
      "Epoch: 15, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1821, TrainQuatLoss: 0.1185  TrainPosLoss: 0.1096 \t TestPoseLoss: 0.1406, TestQuatLoss: 0.1039, TestPosLoss: 0.0842\n",
      "Epoch: 16, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1725, TrainQuatLoss: 0.1125  TrainPosLoss: 0.1057 \t TestPoseLoss: 0.1316, TestQuatLoss: 0.0989, TestPosLoss: 0.0799\n",
      "Epoch: 17, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1646, TrainQuatLoss: 0.1079  TrainPosLoss: 0.1023 \t TestPoseLoss: 0.1252, TestQuatLoss: 0.0944, TestPosLoss: 0.0772\n",
      "Epoch: 18, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1584, TrainQuatLoss: 0.1038  TrainPosLoss: 0.0997 \t TestPoseLoss: 0.1198, TestQuatLoss: 0.0906, TestPosLoss: 0.0750\n",
      "Epoch: 19, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1519, TrainQuatLoss: 0.0999  TrainPosLoss: 0.0969 \t TestPoseLoss: 0.1148, TestQuatLoss: 0.0866, TestPosLoss: 0.0738\n",
      "Epoch: 20, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1461, TrainQuatLoss: 0.0965  TrainPosLoss: 0.0943 \t TestPoseLoss: 0.1107, TestQuatLoss: 0.0833, TestPosLoss: 0.0719\n",
      "Epoch: 21, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1408, TrainQuatLoss: 0.0931  TrainPosLoss: 0.0921 \t TestPoseLoss: 0.1054, TestQuatLoss: 0.0792, TestPosLoss: 0.0695\n",
      "Epoch: 22, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1360, TrainQuatLoss: 0.0901  TrainPosLoss: 0.0900 \t TestPoseLoss: 0.1017, TestQuatLoss: 0.0767, TestPosLoss: 0.0677\n",
      "Epoch: 23, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1319, TrainQuatLoss: 0.0875  TrainPosLoss: 0.0880 \t TestPoseLoss: 0.0993, TestQuatLoss: 0.0739, TestPosLoss: 0.0670\n",
      "Epoch: 24, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1280, TrainQuatLoss: 0.0851  TrainPosLoss: 0.0860 \t TestPoseLoss: 0.0951, TestQuatLoss: 0.0712, TestPosLoss: 0.0646\n",
      "Epoch: 25, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1240, TrainQuatLoss: 0.0827  TrainPosLoss: 0.0841 \t TestPoseLoss: 0.0921, TestQuatLoss: 0.0692, TestPosLoss: 0.0630\n",
      "Epoch: 26, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1208, TrainQuatLoss: 0.0808  TrainPosLoss: 0.0825 \t TestPoseLoss: 0.0904, TestQuatLoss: 0.0677, TestPosLoss: 0.0624\n",
      "Epoch: 27, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1175, TrainQuatLoss: 0.0786  TrainPosLoss: 0.0810 \t TestPoseLoss: 0.0881, TestQuatLoss: 0.0657, TestPosLoss: 0.0617\n",
      "Epoch: 28, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1149, TrainQuatLoss: 0.0770  TrainPosLoss: 0.0798 \t TestPoseLoss: 0.0864, TestQuatLoss: 0.0651, TestPosLoss: 0.0604\n",
      "Epoch: 29, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1124, TrainQuatLoss: 0.0755  TrainPosLoss: 0.0784 \t TestPoseLoss: 0.0846, TestQuatLoss: 0.0627, TestPosLoss: 0.0596\n",
      "Epoch: 30, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1100, TrainQuatLoss: 0.0740  TrainPosLoss: 0.0773 \t TestPoseLoss: 0.0825, TestQuatLoss: 0.0603, TestPosLoss: 0.0593\n",
      "Epoch: 31, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1079, TrainQuatLoss: 0.0724  TrainPosLoss: 0.0763 \t TestPoseLoss: 0.0804, TestQuatLoss: 0.0595, TestPosLoss: 0.0581\n",
      "Epoch: 32, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1056, TrainQuatLoss: 0.0710  TrainPosLoss: 0.0751 \t TestPoseLoss: 0.0786, TestQuatLoss: 0.0577, TestPosLoss: 0.0574\n",
      "Epoch: 33, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1040, TrainQuatLoss: 0.0698  TrainPosLoss: 0.0744 \t TestPoseLoss: 0.0785, TestQuatLoss: 0.0575, TestPosLoss: 0.0572\n",
      "Epoch: 34, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1024, TrainQuatLoss: 0.0687  TrainPosLoss: 0.0737 \t TestPoseLoss: 0.0775, TestQuatLoss: 0.0573, TestPosLoss: 0.0569\n",
      "Epoch: 35, Learning Rate: 0.00100000 \n",
      " TrainPoseLoss: 0.1002, TrainQuatLoss: 0.0674  TrainPosLoss: 0.0724 \t TestPoseLoss: 0.0763, TestQuatLoss: 0.0560, TestPosLoss: 0.0561\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-03b8fe185d37>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mpred_quat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_markers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mloss_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_markers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_not_shuffled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss_quat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function_quat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_quat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquat_truth_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_truth_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1BNNf-R7nHRt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "19a48b7e-99f6-439c-9ecf-d6d7c07def88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "posQuatColab.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
